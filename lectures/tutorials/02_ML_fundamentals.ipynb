{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7811dc1d-c6c3-460e-b073-ea6e1955113e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](../img/330-banner.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484f2995-151e-4b9d-be4c-343f7bc8dc77",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Tutorial 2\n",
    "\n",
    "UBC 2024-25\n",
    "\n",
    "## Outline\n",
    "\n",
    "During this tutorial, we will focus on the ideas of generalization, training, validation and test scores, and cross-validation. Additionally, we will play with different algorithms and see how their hyperparameters affect their complexity.\n",
    "\n",
    "All questions can be discussed with your classmates and the TAs - this is not a graded exercise!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd5db5d-5339-4a9c-9343-824e3325a3d7",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69677356-d886-42f0-9f80-db95323471dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.abspath(\"..\"), \"code\"))\n",
    "# from plotting_functions import *\n",
    "from utils import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "DATA_DIR = os.path.join(os.path.abspath(\"..\"), \"data/\")\n",
    "pd.set_option(\"display.max_colwidth\", 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef33d48-69f6-4f2a-8f8d-be05172954a0",
   "metadata": {},
   "source": [
    "We are going to use the King County housing sale prediction data from the course introduction video. You can download the data from [here](https://www.kaggle.com/datasets/harlfoxem/housesalesprediction).\n",
    "\n",
    "This is a **regression** problem:  we are trying to predict the sale price of each house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65141e00-6157-4cfe-bc13-4fb314e60ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21608</th>\n",
       "      <td>263000018</td>\n",
       "      <td>20140521T000000</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1530</td>\n",
       "      <td>1131</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1530</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98103</td>\n",
       "      <td>47.6993</td>\n",
       "      <td>-122.346</td>\n",
       "      <td>1530</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21609</th>\n",
       "      <td>6600060120</td>\n",
       "      <td>20150223T000000</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2310</td>\n",
       "      <td>5813</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2310</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>98146</td>\n",
       "      <td>47.5107</td>\n",
       "      <td>-122.362</td>\n",
       "      <td>1830</td>\n",
       "      <td>7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21610</th>\n",
       "      <td>1523300141</td>\n",
       "      <td>20140623T000000</td>\n",
       "      <td>402101.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1350</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5944</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21611</th>\n",
       "      <td>291310100</td>\n",
       "      <td>20150116T000000</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1600</td>\n",
       "      <td>2388</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>98027</td>\n",
       "      <td>47.5345</td>\n",
       "      <td>-122.069</td>\n",
       "      <td>1410</td>\n",
       "      <td>1287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21612</th>\n",
       "      <td>1523300157</td>\n",
       "      <td>20141015T000000</td>\n",
       "      <td>325000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1076</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5941</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21613 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id             date     price  bedrooms  bathrooms  \\\n",
       "0      7129300520  20141013T000000  221900.0         3       1.00   \n",
       "1      6414100192  20141209T000000  538000.0         3       2.25   \n",
       "2      5631500400  20150225T000000  180000.0         2       1.00   \n",
       "3      2487200875  20141209T000000  604000.0         4       3.00   \n",
       "4      1954400510  20150218T000000  510000.0         3       2.00   \n",
       "...           ...              ...       ...       ...        ...   \n",
       "21608   263000018  20140521T000000  360000.0         3       2.50   \n",
       "21609  6600060120  20150223T000000  400000.0         4       2.50   \n",
       "21610  1523300141  20140623T000000  402101.0         2       0.75   \n",
       "21611   291310100  20150116T000000  400000.0         3       2.50   \n",
       "21612  1523300157  20141015T000000  325000.0         2       0.75   \n",
       "\n",
       "       sqft_living  sqft_lot  floors  waterfront  view  ...  grade  \\\n",
       "0             1180      5650     1.0           0     0  ...      7   \n",
       "1             2570      7242     2.0           0     0  ...      7   \n",
       "2              770     10000     1.0           0     0  ...      6   \n",
       "3             1960      5000     1.0           0     0  ...      7   \n",
       "4             1680      8080     1.0           0     0  ...      8   \n",
       "...            ...       ...     ...         ...   ...  ...    ...   \n",
       "21608         1530      1131     3.0           0     0  ...      8   \n",
       "21609         2310      5813     2.0           0     0  ...      8   \n",
       "21610         1020      1350     2.0           0     0  ...      7   \n",
       "21611         1600      2388     2.0           0     0  ...      8   \n",
       "21612         1020      1076     2.0           0     0  ...      7   \n",
       "\n",
       "       sqft_above  sqft_basement  yr_built  yr_renovated  zipcode      lat  \\\n",
       "0            1180              0      1955             0    98178  47.5112   \n",
       "1            2170            400      1951          1991    98125  47.7210   \n",
       "2             770              0      1933             0    98028  47.7379   \n",
       "3            1050            910      1965             0    98136  47.5208   \n",
       "4            1680              0      1987             0    98074  47.6168   \n",
       "...           ...            ...       ...           ...      ...      ...   \n",
       "21608        1530              0      2009             0    98103  47.6993   \n",
       "21609        2310              0      2014             0    98146  47.5107   \n",
       "21610        1020              0      2009             0    98144  47.5944   \n",
       "21611        1600              0      2004             0    98027  47.5345   \n",
       "21612        1020              0      2008             0    98144  47.5941   \n",
       "\n",
       "          long  sqft_living15  sqft_lot15  \n",
       "0     -122.257           1340        5650  \n",
       "1     -122.319           1690        7639  \n",
       "2     -122.233           2720        8062  \n",
       "3     -122.393           1360        5000  \n",
       "4     -122.045           1800        7503  \n",
       "...        ...            ...         ...  \n",
       "21608 -122.346           1530        1509  \n",
       "21609 -122.362           1830        7200  \n",
       "21610 -122.299           1020        2007  \n",
       "21611 -122.069           1410        1287  \n",
       "21612 -122.299           1020        1357  \n",
       "\n",
       "[21613 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df = pd.read_csv(DATA_DIR + 'kc_house_data.csv')\n",
    "housing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68149c4c-0a63-4e6f-b3a2-8fe32157f6ef",
   "metadata": {},
   "source": [
    "## EDA: Exploratory Data Analysis\n",
    "\n",
    "Before tackling any data science problem, the first step is always familiarizing with the dataset.\n",
    "\n",
    "### <font color='red'>Question 1</font>\n",
    "\n",
    "Run the cells below and answer the following questions:\n",
    "- How many samples are included in the dataset? 21613\n",
    "- Are the columns the correct type (strings as strings, numbers as numbers)? Do we have missing data?\n",
    "- What is the average sale price?\n",
    "- Looking at the column names, do you think some of them are not helpful in predicting the price of the house?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42d6c070-0031-46b7-b300-66beaa646b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21613"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many data points do we have? \n",
    "housing_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cda2c2a5-aaab-441b-a340-461598b79eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21613 entries, 0 to 21612\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   id             21613 non-null  int64  \n",
      " 1   date           21613 non-null  object \n",
      " 2   price          21613 non-null  float64\n",
      " 3   bedrooms       21613 non-null  int64  \n",
      " 4   bathrooms      21613 non-null  float64\n",
      " 5   sqft_living    21613 non-null  int64  \n",
      " 6   sqft_lot       21613 non-null  int64  \n",
      " 7   floors         21613 non-null  float64\n",
      " 8   waterfront     21613 non-null  int64  \n",
      " 9   view           21613 non-null  int64  \n",
      " 10  condition      21613 non-null  int64  \n",
      " 11  grade          21613 non-null  int64  \n",
      " 12  sqft_above     21613 non-null  int64  \n",
      " 13  sqft_basement  21613 non-null  int64  \n",
      " 14  yr_built       21613 non-null  int64  \n",
      " 15  yr_renovated   21613 non-null  int64  \n",
      " 16  zipcode        21613 non-null  int64  \n",
      " 17  lat            21613 non-null  float64\n",
      " 18  long           21613 non-null  float64\n",
      " 19  sqft_living15  21613 non-null  int64  \n",
      " 20  sqft_lot15     21613 non-null  int64  \n",
      "dtypes: float64(5), int64(15), object(1)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# What is the type and count for each column?\n",
    "housing_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b50f5be-2d16-468b-8e5d-ea27521ec7d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.161300e+04</td>\n",
       "      <td>2.161300e+04</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>2.161300e+04</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.580302e+09</td>\n",
       "      <td>5.400881e+05</td>\n",
       "      <td>3.370842</td>\n",
       "      <td>2.114757</td>\n",
       "      <td>2079.899736</td>\n",
       "      <td>1.510697e+04</td>\n",
       "      <td>1.494309</td>\n",
       "      <td>0.007542</td>\n",
       "      <td>0.234303</td>\n",
       "      <td>3.409430</td>\n",
       "      <td>7.656873</td>\n",
       "      <td>1788.390691</td>\n",
       "      <td>291.509045</td>\n",
       "      <td>1971.005136</td>\n",
       "      <td>84.402258</td>\n",
       "      <td>98077.939805</td>\n",
       "      <td>47.560053</td>\n",
       "      <td>-122.213896</td>\n",
       "      <td>1986.552492</td>\n",
       "      <td>12768.455652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.876566e+09</td>\n",
       "      <td>3.671272e+05</td>\n",
       "      <td>0.930062</td>\n",
       "      <td>0.770163</td>\n",
       "      <td>918.440897</td>\n",
       "      <td>4.142051e+04</td>\n",
       "      <td>0.539989</td>\n",
       "      <td>0.086517</td>\n",
       "      <td>0.766318</td>\n",
       "      <td>0.650743</td>\n",
       "      <td>1.175459</td>\n",
       "      <td>828.090978</td>\n",
       "      <td>442.575043</td>\n",
       "      <td>29.373411</td>\n",
       "      <td>401.679240</td>\n",
       "      <td>53.505026</td>\n",
       "      <td>0.138564</td>\n",
       "      <td>0.140828</td>\n",
       "      <td>685.391304</td>\n",
       "      <td>27304.179631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000102e+06</td>\n",
       "      <td>7.500000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>5.200000e+02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98001.000000</td>\n",
       "      <td>47.155900</td>\n",
       "      <td>-122.519000</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>651.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.123049e+09</td>\n",
       "      <td>3.219500e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1427.000000</td>\n",
       "      <td>5.040000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1951.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98033.000000</td>\n",
       "      <td>47.471000</td>\n",
       "      <td>-122.328000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.904930e+09</td>\n",
       "      <td>4.500000e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>1910.000000</td>\n",
       "      <td>7.618000e+03</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1560.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1975.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98065.000000</td>\n",
       "      <td>47.571800</td>\n",
       "      <td>-122.230000</td>\n",
       "      <td>1840.000000</td>\n",
       "      <td>7620.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.308900e+09</td>\n",
       "      <td>6.450000e+05</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2550.000000</td>\n",
       "      <td>1.068800e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2210.000000</td>\n",
       "      <td>560.000000</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98118.000000</td>\n",
       "      <td>47.678000</td>\n",
       "      <td>-122.125000</td>\n",
       "      <td>2360.000000</td>\n",
       "      <td>10083.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.900000e+09</td>\n",
       "      <td>7.700000e+06</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13540.000000</td>\n",
       "      <td>1.651359e+06</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>9410.000000</td>\n",
       "      <td>4820.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>98199.000000</td>\n",
       "      <td>47.777600</td>\n",
       "      <td>-121.315000</td>\n",
       "      <td>6210.000000</td>\n",
       "      <td>871200.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         price      bedrooms     bathrooms   sqft_living  \\\n",
       "count  2.161300e+04  2.161300e+04  21613.000000  21613.000000  21613.000000   \n",
       "mean   4.580302e+09  5.400881e+05      3.370842      2.114757   2079.899736   \n",
       "std    2.876566e+09  3.671272e+05      0.930062      0.770163    918.440897   \n",
       "min    1.000102e+06  7.500000e+04      0.000000      0.000000    290.000000   \n",
       "25%    2.123049e+09  3.219500e+05      3.000000      1.750000   1427.000000   \n",
       "50%    3.904930e+09  4.500000e+05      3.000000      2.250000   1910.000000   \n",
       "75%    7.308900e+09  6.450000e+05      4.000000      2.500000   2550.000000   \n",
       "max    9.900000e+09  7.700000e+06     33.000000      8.000000  13540.000000   \n",
       "\n",
       "           sqft_lot        floors    waterfront          view     condition  \\\n",
       "count  2.161300e+04  21613.000000  21613.000000  21613.000000  21613.000000   \n",
       "mean   1.510697e+04      1.494309      0.007542      0.234303      3.409430   \n",
       "std    4.142051e+04      0.539989      0.086517      0.766318      0.650743   \n",
       "min    5.200000e+02      1.000000      0.000000      0.000000      1.000000   \n",
       "25%    5.040000e+03      1.000000      0.000000      0.000000      3.000000   \n",
       "50%    7.618000e+03      1.500000      0.000000      0.000000      3.000000   \n",
       "75%    1.068800e+04      2.000000      0.000000      0.000000      4.000000   \n",
       "max    1.651359e+06      3.500000      1.000000      4.000000      5.000000   \n",
       "\n",
       "              grade    sqft_above  sqft_basement      yr_built  yr_renovated  \\\n",
       "count  21613.000000  21613.000000   21613.000000  21613.000000  21613.000000   \n",
       "mean       7.656873   1788.390691     291.509045   1971.005136     84.402258   \n",
       "std        1.175459    828.090978     442.575043     29.373411    401.679240   \n",
       "min        1.000000    290.000000       0.000000   1900.000000      0.000000   \n",
       "25%        7.000000   1190.000000       0.000000   1951.000000      0.000000   \n",
       "50%        7.000000   1560.000000       0.000000   1975.000000      0.000000   \n",
       "75%        8.000000   2210.000000     560.000000   1997.000000      0.000000   \n",
       "max       13.000000   9410.000000    4820.000000   2015.000000   2015.000000   \n",
       "\n",
       "            zipcode           lat          long  sqft_living15     sqft_lot15  \n",
       "count  21613.000000  21613.000000  21613.000000   21613.000000   21613.000000  \n",
       "mean   98077.939805     47.560053   -122.213896    1986.552492   12768.455652  \n",
       "std       53.505026      0.138564      0.140828     685.391304   27304.179631  \n",
       "min    98001.000000     47.155900   -122.519000     399.000000     651.000000  \n",
       "25%    98033.000000     47.471000   -122.328000    1490.000000    5100.000000  \n",
       "50%    98065.000000     47.571800   -122.230000    1840.000000    7620.000000  \n",
       "75%    98118.000000     47.678000   -122.125000    2360.000000   10083.000000  \n",
       "max    98199.000000     47.777600   -121.315000    6210.000000  871200.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe gives a summary of the numerical features in the dataframe\n",
    "housing_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e31509f7-d455-48a7-a89e-1c515f28aade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'date', 'price', 'bedrooms', 'bathrooms', 'sqft_living',\n",
       "       'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
       "       'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n",
       "       'lat', 'long', 'sqft_living15', 'sqft_lot15'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the columns in the dataset? \n",
    "housing_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199c1b64-6187-4a21-9f8e-4dfefa563da7",
   "metadata": {},
   "source": [
    "EDA can be much more extensive, but for this exercise we will stop here. \n",
    "\n",
    "Let's agree to drop the `ID`, `date`, and `zipcode` columns. ID is not helpful for prediction. Date may be interesting but it is a type of information that requires special handling, which we will see later in the course. Zipcode could also be interesting, but it is a categorical variable with too many values, and we do not know how to handle this yet. We will keep all the other (numerical) features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d864d06c-9f16-49b2-886c-1f03baf0c57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unused features, and separating features and target\n",
    "\n",
    "X = housing_df.drop(columns = ['id', 'date', 'zipcode', 'price'])#id, date and zipcode is not useful\n",
    "y = housing_df['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8164b4bc-41b4-4b3f-9160-f967d039e37e",
   "metadata": {},
   "source": [
    "## Data splitting\n",
    "\n",
    "As discussed in class, it is important for models to generalize to unseen data, therefore we will set aside a subset of samples to evaluate the model on samples it has not been trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57071e10-9339-4d29-95f7-1d21a7a0e3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b58dd9-42c1-4d23-a2b3-cae4416af167",
   "metadata": {},
   "source": [
    "## <font color='red'>Question 2: Baseline model</font>\n",
    "\n",
    "As always, we will start by building a baseline model to use as reference. Build and score your model in the cell below. Remember that this is a *regression* problem, so you will not use `DummyClassifier`, but the corresponding model for regression!\n",
    "\n",
    "Also, remember to score the model on the training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ba1572-9cb8-47f9-b3a3-89a812eb705d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skelarn.dummy import DummyRegressor\n",
    "dummy_clf = DummyRegressor(strategy =\"mean\")\n",
    "dummy_clf.fit(X_train,y_train)\n",
    "baseline_acc_train = dummy.clf\n",
    "baseline_acc = dumy_clf.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75c0863-af21-4286-8942-435f5acb69f6",
   "metadata": {},
   "source": [
    "**Note:** did you check the value of a prediction from the baseline model? It is very close to the mean of `price`, as expected! But not exactly the same, as we set some samples aside for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44e5f3c-bf46-46df-b6f5-82d69524c489",
   "metadata": {},
   "source": [
    "## <font color='red'>Question 3: Decision tree</font>\n",
    "\n",
    "Let's now try a more sofisticated approach. We will use a `DecisionTreeRegressor` to predict the house prices. Run the code below and answer the following questions:\n",
    "- Why is there a large gap between train and test scores?\n",
    "- What would be the effect of increasing or decreasing test_size? How would that affect your confidence in the test score?\n",
    "- Why are we setting the random_state? Is it a good idea to try a bunch of values for the random_state and pick the one which gives the best scores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8567d777-f497-4fd8-94b5-2156941b2483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a class object \n",
    "dt = DecisionTreeRegressor(random_state=123)\n",
    "\n",
    "# Train a decision tree on X_train, y_train\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Score on the train set\n",
    "dt.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6386cd71-c772-4cc0-8760-b4ba0b27bdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score on the test set\n",
    "dt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212ce3a1-2e61-4f99-bfc2-f6e06040f2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are curious, you can see the depth of this tree - what do you think of this value? What does it tell us?\n",
    "dt.get_depth()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e0cdae-a7e1-45fb-ad32-4c7caae077f3",
   "metadata": {},
   "source": [
    "## <font color='red'>Question 4: Hyperparameter tuning</font>\n",
    "\n",
    "The model above is showing clear signs of **overfitting:** it learned *too much* from the training set, including noise and errors, and that has a negative impact on its ability to predict unseen samples. To fix his, we are going to force the tree to *learn less* by reducing its maximum depth.\n",
    "\n",
    "Before we do that, we will further split the training set in training and validation, to avoid using the test set for hyperparameter tuning (which means breaking the golden rule - the test set can not influence the model in any way, not even in the choice of hyperparameter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abb2cc6-08af-410a-a04d-db9ffb68b9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a validation set \n",
    "X_tr, X_valid, y_tr, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67ddad4-1565-4b37-99c3-356843555462",
   "metadata": {},
   "source": [
    "Now, we will try different depth values and choose the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dbe362-4cb2-45d2-b247-8efd11843b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_scores = []\n",
    "valid_scores = []\n",
    "depths = np.arange(1, 35, 2)\n",
    "\n",
    "for depth in depths:  \n",
    "    # Create and fit a decision tree model for the given depth  \n",
    "    dt = DecisionTreeRegressor(max_depth=depth, random_state=123)\n",
    "\n",
    "    dt.fit(X_tr, y_tr)\n",
    "    # Calculate and append r2 scores on the training and validation sets\n",
    "    tr_scores.append(dt.score(X_tr, y_tr))    \n",
    "    valid_scores.append(dt.score(X_valid, y_valid))\n",
    "    \n",
    "results_single_valid_df = pd.DataFrame({\"train_score\": tr_scores, \n",
    "                           \"valid_score\": valid_scores},index = depths)\n",
    "results_single_valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfec4be0-9cbb-4406-8780-706409c4c827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results above\n",
    "results_single_valid_df[['train_score', 'valid_score']].plot(ylabel='r2 scores');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a277140-2a82-4b50-aab9-e340adb0caa0",
   "metadata": {},
   "source": [
    "Answer the following questions:\n",
    "- What is the best tree depth? How did you choose this value?\n",
    "- How would you describe gap between training and validation set for smaller depth values? And what about higher values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595af60c-6e6a-476d-856e-9f64b7ee103c",
   "metadata": {},
   "source": [
    "## <font color='red'>Question 5: Cross-validation</font>\n",
    "\n",
    "Our validation set is not very big - only about 3500 samples. It is not exceedingly small, but it could still allow for some variance in the score if a different set was picked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6117382a-f74f-491d-bafa-e04e02a09a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check the size of the validation set\n",
    "X_valid.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dee3af4-792c-43de-9e14-aa3051d1223d",
   "metadata": {},
   "source": [
    "In the cell below, we are going to observe this phenomenon, by using `cross_validate` on our best tree candidate (`max_depth` = 11). See how the test_scores change with every different fold?\n",
    "\n",
    "**Notes:** \n",
    "- `cross_validate` has no concept of validation set, and it calls it test set instead. For our purposes, test_scores are validation scores\n",
    "- Because we are using cross-validation, we can use the original X_train set, before we further divided it in training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c2b887-7f9e-4236-b1d5-bb51913a9026",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_best = DecisionTreeRegressor(max_depth=11, random_state=123)\n",
    "\n",
    "scores = cross_validate(dt_best, X_train, y_train, cv=10, return_train_score=True)\n",
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d4e986-3b07-42a4-add5-fed00cca68b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average of above values\n",
    "pd.DataFrame(pd.DataFrame(scores).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4553fc04-8b64-4f8a-86c7-05a4c4afac8f",
   "metadata": {},
   "source": [
    "Answer the following questions:\n",
    "- What is the highest validation score? And lowest? How far are they from the mean value? Would it have been possible for us to see any of these scores if we used only one validation set?\n",
    "- How did cross-validation help us getting a more robust score measure?\n",
    "- Fold 8 has the best validation score. Shouldn't we just use the model fitted on this particular training fold?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406b5988-880b-4352-aeef-f1df66dbf551",
   "metadata": {},
   "source": [
    "#### Final note\n",
    "\n",
    "Cross-validation is often used in the context of hyperparameter tuning, such as in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89cada5-c241-4d66-9d97-b5cb293b426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = np.arange(1, 35, 2)\n",
    "\n",
    "cv_train_scores = []\n",
    "cv_valid_scores = []\n",
    "for depth in depths: \n",
    "    # Create and fit a decision tree model for the given depth   \n",
    "    dt = DecisionTreeRegressor(max_depth = depth, random_state=123)\n",
    "\n",
    "    # Carry out cross-validation\n",
    "    results = cross_validate(dt, X_train, y_train, cv=5, return_train_score=True)\n",
    "    cv_train_scores.append(results['train_score'].mean())\n",
    "    cv_valid_scores.append(results['test_score'].mean())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63ba26d-d68a-4c19-bcd5-17365a8eae18",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({\"train_score\": cv_train_scores, \n",
    "                           \"valid_score\": cv_valid_scores\n",
    "                           },\n",
    "                           index=depths\n",
    "                            )\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dad2917-7282-4d66-8146-a6159d3bb30a",
   "metadata": {},
   "source": [
    "Thanks to cross-validation, the validation scores that you see in this example are more stable than the scores one could obtain using a single validation set (and again, 11 seems to be the best depth for this problem).\n",
    "\n",
    "**The purpose of cross-validation, however, is not hyperparameter tuning.** Cross-validation does not produce the best hyperparameters for the model. It produces a more robust score for a specific model and a specific set of hyperparameters, set by us.\n",
    "\n",
    "**Because they are often seen together, people can mistake cross-validation and hyperparameter tuning as being the same thing.** But because you did this tutorial, you will not get confused anymore 😊."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb095c47-1948-453e-93b2-63a7383e2c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last step: final training and scoring on test set. \n",
    "\n",
    "# This is the score on completely unseen samples. \n",
    "\n",
    "dt = DecisionTreeRegressor(max_depth=11, random_state=123)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "dt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3f535f-c243-4187-82e5-57d27ec13108",
   "metadata": {},
   "source": [
    "## <font color='red'>Question 6: Hyperparameters playground</font>\n",
    "\n",
    "We are now going to look at a different problem - a classification one - to see the impact on different hyperparameters on model learning.\n",
    "\n",
    "In this interactive playground, you will investigate how various algorithms create decision boundaries to distinguish between Iris flower species using their sepal length and width as features. By adjusting the parameters, you can observe how the decision boundaries change, which can result in either overfitting (where the model fits the training data too closely) or underfitting (where the model is too simplistic).\n",
    "\n",
    "- With **k-Nearest Neighbours ($k$-NN)**, you'll determine how many neighboring flowers to consult. Should we rely on a single nearest neighbor? Or should we consider a wider group? \n",
    "\n",
    "- With **Support Vector Machine (SVM)** using the RBF kernel, you'll tweak the hyperparameters `C` and `gamma` to explore the tightrope walk between overly complex boundaries (that might overfit) and overly broad ones (that might underfit).\n",
    "  \n",
    "- With **Decision trees**, you'll observe the effect of `max_depth` on the decision boundary. \n",
    "\n",
    "Observe the process of crafting and refining decision boundaries, one parameter at a time! Be sure to take breaks to reflect on the results you are observing, and answer the following questions:\n",
    "\n",
    "- For each hyperparameter, write down the relationship between value and model complexity (does the complexity increase with the value or vice-versa?).\n",
    "- What hyperparameter value (or combination of values) seems to give the best results for each model? Is this problem better solved by complex models, or simpler ones? **Hint:** the dataset is small, which increases the risk of overfitting if we pick too complex models.\n",
    "- Describe the appearance of the decision boundaries for each model. Which model presents as smooth, curved lines? Which one looks like a very fragmented line? Note that the appearance will vary as you change the hyperparameter values, but you should be able to spot some common patterns..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8769f768-a3c3-4d61-94a7-bedb98b6d6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.figure import Figure\n",
    "\n",
    "import panel as pn\n",
    "from panel import widgets\n",
    "from panel.interact import interact\n",
    "\n",
    "pn.extension()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from ipywidgets import interact, FloatLogSlider, IntSlider\n",
    "import mglearn\n",
    "\n",
    "\n",
    "# Load dataset and preprocessing\n",
    "iris = load_iris(as_frame=True)\n",
    "iris_df = iris.data\n",
    "iris_df['species'] = iris.target\n",
    "iris_df = iris_df[iris_df['species'] > 0]\n",
    "X, y = iris_df[['sepal length (cm)', 'sepal width (cm)']], iris_df['species']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=123)\n",
    "\n",
    "\n",
    "# Common plot settings\n",
    "def plot_results(model, X_train, y_train, title, ax):\n",
    "    mglearn.plots.plot_2d_separator(model, X_train.values, fill=True, alpha=0.4, ax=ax);\n",
    "    mglearn.discrete_scatter(\n",
    "        X_train[\"sepal length (cm)\"], X_train[\"sepal width (cm)\"], y_train, s=6, ax=ax\n",
    "    );\n",
    "    ax.set_xlabel(\"sepal length (cm)\", fontsize=12);\n",
    "    ax.set_ylabel(\"sepal width (cm)\", fontsize=12);\n",
    "    train_score = np.round(model.score(X_train.values, y_train), 2)\n",
    "    test_score = np.round(model.score(X_test.values, y_test), 2)\n",
    "    ax.set_title(\n",
    "        f\"{title}\\n train score = {train_score}\\ntest score = {test_score}\", fontsize=8\n",
    "    );\n",
    "    pass\n",
    "\n",
    "\n",
    "# Widgets for SVM, k-NN, and Decision Tree\n",
    "c_widget = pn.widgets.FloatSlider(\n",
    "    value=1.0, start=1, end=5, step=0.1, name=\"C (log scale)\"\n",
    ")\n",
    "gamma_widget = pn.widgets.FloatSlider(\n",
    "    value=1.0, start=-3, end=5, step=0.1, name=\"Gamma (log scale)\"\n",
    ")\n",
    "n_neighbors_widget = pn.widgets.IntSlider(\n",
    "    start=1, end=40, step=1, value=5, name=\"n_neighbors\"\n",
    ")\n",
    "max_depth_widget = pn.widgets.IntSlider(\n",
    "    start=1, end=20, step=1, value=3, name=\"max_depth\"\n",
    ")\n",
    "\n",
    "\n",
    "# The update function to create the plots\n",
    "def update_plots(c, gamma=1.0, n_neighbors=5, max_depth=3):\n",
    "    c_log = round(10**c, 2)  # Transform C to logarithmic scale\n",
    "    gamma_log = round(10**gamma, 2)   # Transform Gamma to logarithmic scale\n",
    "\n",
    "    fig = Figure(figsize=(8, 2))\n",
    "    axes = fig.subplots(1, 3)\n",
    "\n",
    "    models = [\n",
    "        SVC(C=c_log, gamma=gamma_log, random_state=42),\n",
    "        KNeighborsClassifier(n_neighbors=n_neighbors),\n",
    "        DecisionTreeClassifier(max_depth=max_depth, random_state=42),\n",
    "    ]\n",
    "    titles = [\n",
    "        f\"SVM (C={c_log}, gamma={gamma_log})\",\n",
    "        f\"k-NN (n_neighbors={n_neighbors})\",\n",
    "        f\"Decision Tree (max_depth={max_depth})\",\n",
    "    ]\n",
    "    for model, title, ax in zip(models, titles, axes):\n",
    "        model.fit(X_train.values, y_train)\n",
    "        plot_results(model, X_train, y_train, title, ax);\n",
    "    # print(c, gamma, n_neighbors, max_depth)\n",
    "    return pn.pane.Matplotlib(fig, tight=True);\n",
    "\n",
    "\n",
    "# Bind the function to the panel widgets\n",
    "interactive_plot = pn.bind(\n",
    "    update_plots,\n",
    "    c=c_widget.param.value_throttled,\n",
    "    gamma=gamma_widget.param.value_throttled,\n",
    "    n_neighbors=n_neighbors_widget.param.value_throttled,\n",
    "    max_depth=max_depth_widget.param.value_throttled,\n",
    ")\n",
    "\n",
    "# Layout the widgets and the plot\n",
    "dashboard = pn.Column(\n",
    "    pn.Row(c_widget, n_neighbors_widget),\n",
    "    pn.Row(gamma_widget, max_depth_widget),\n",
    "    interactive_plot,\n",
    ")\n",
    "\n",
    "# Display the interactive dashboard\n",
    "dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a499243-8b9c-4601-93a2-b133486f59ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cpsc330] *",
   "language": "python",
   "name": "conda-env-cpsc330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
